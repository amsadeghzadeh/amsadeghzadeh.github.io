{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "carlini.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amsadeghzadeh/amsadeghzadeh.github.io/blob/master/AP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kcH4PimFGBqC",
        "colab_type": "code",
        "outputId": "3d6a09b3-8364-413b-80ac-bea7bea6e3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yygtNem0Iwe5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/My\\ Drive/carlini/nn_robust_attacks/DF/train_DF_model.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4WjJyIxOMlRm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/env/python:/content/drive/My\\ Drive/adversarial_patch/my_ap/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "89H4lYEE5x5P",
        "colab_type": "code",
        "outputId": "8328923c-32f9-43f8-bfb4-7ebefeb25117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!echo $PYTHONPATH"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/env/python:/env/python:/content/drive/My\\ Drive/adversarial_patch/my_ap/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5X05JmuhKEbf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 drive/My\\ Drive/carlini/nn_robust_attacks/my.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pIrrncV4a2Ww",
        "colab_type": "code",
        "outputId": "7c4abb34-e329-4ebc-9268-de24586a025e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/nottombrown/imagenet_stubs --upgrade\n",
        "\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/nottombrown/imagenet_stubs\n",
            "  Cloning https://github.com/nottombrown/imagenet_stubs to /tmp/pip-req-build-l9guurob\n",
            "Building wheels for collected packages: imagenet-stubs\n",
            "  Running setup.py bdist_wheel for imagenet-stubs ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-0i7iy785/wheels/ae/51/e7/c1cfa8692ea864410aa778b169fc7766af073ac52a1bc23301\n",
            "Successfully built imagenet-stubs\n",
            "Installing collected packages: imagenet-stubs\n",
            "Successfully installed imagenet-stubs-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NNBbHAmHZO5f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/My\\ Drive/adversarial_patch/my_ap/WF_AP.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ICGuNWA_gvwh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f068d6e-2826-4c3b-dd8b-cab6311a86b5"
      },
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My\\ Drive/adversarial_patch/my_ap"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/adversarial_patch/my_ap\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l-Mb8A4Zy1_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9c82802-eba2-46b2-9f8c-b90865ed7b01"
      },
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/adversarial_patch/my_ap'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "9Tm9d-9Sw09_",
        "colab_type": "code",
        "outputId": "774c8ab5-32d6-4928-cbef-c348c3354ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4539
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import PIL.Image\n",
        "import time\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "from StubImagenet import DFDataLoader\n",
        "from meta_model import MetaModel\n",
        "from display import DF_report,make_adversarial_training_data\n",
        "from save_load import save_obj,load_obj\n",
        "\n",
        "\n",
        "from DF.model_kears import  DF_keras_Model\n",
        "from train_DF_model import train\n",
        "\n",
        "\n",
        "DF_NB_CLASSES = 95\n",
        "TRACE_LENGTH = 5000\n",
        "TRACE_MASK_LENGTH = 100\n",
        "\n",
        "PATCH_SHAPE = (299, 299, 3)\n",
        "TRACE_PATCH_SHAPE=(TRACE_LENGTH,1)\n",
        "BATCH_SIZE = 64\n",
        "INPUT_SHAPE = (TRACE_LENGTH,1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "MODEL_NAMES = ['DF']\n",
        "\n",
        "TARGET_LABEL = 73\n",
        "\n",
        "\n",
        "LEARNING_RATE = 20\n",
        "\n",
        "print(MODEL_NAMES)\n",
        "\n",
        "# Data augmentation\n",
        "# Empirically found that training with a very wide scale range works well\n",
        "# as a default\n",
        "SCALE_MIN = 0.\n",
        "SCALE_MAX = 12.\n",
        "\n",
        "\n",
        "# Local data dir to write files to\n",
        "DATA_DIR = 'adversarial_patch_things'\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "#for example_image in image_loader.get_images()[:2]:\n",
        "    #print(\"Example true image:\")\n",
        "    #show(example_image)\n",
        "############################################################################################\n",
        "####################################################################################################\n",
        "\n",
        "\n",
        "# @title class ModelState()\n",
        "\n",
        "\n",
        "def get_peace_mask(shape):\n",
        "    path = osp.join(DATA_DIR, \"peace_sign.png\")\n",
        "    pic = PIL.Image.open(path)\n",
        "    pic = pic.resize(shape[:2], PIL.Image.ANTIALIAS)\n",
        "    if path.endswith('.png'):\n",
        "        ch = 4\n",
        "    else:\n",
        "        ch = 3\n",
        "    pic = np.array(pic.getdata()).reshape(pic.size[0], pic.size[1], ch)\n",
        "    pic = pic / 127.5 - 1\n",
        "    pic = pic[:, :, 3]\n",
        "\n",
        "    peace_mask = (pic + 1.0) / 2\n",
        "    peace_mask = np.expand_dims(peace_mask, 2)\n",
        "    peace_mask = np.broadcast_to(peace_mask, shape)\n",
        "    return peace_mask\n",
        "\n",
        "\n",
        "\n",
        "def _line_mask(shape, sharpness=40):\n",
        "    \"\"\"Return a circular mask of a given shape\"\"\"\n",
        "    mask = np.zeros(shape,dtype=np.float32)\n",
        "    mask[np.arange(0,TRACE_MASK_LENGTH)] = 1\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _DF_gen_target_ys(target_cls = TARGET_LABEL):\n",
        "    label = target_cls\n",
        "    y_one_hot = np.zeros(DF_NB_CLASSES)\n",
        "    y_one_hot[label] = 1.0\n",
        "    y_one_hot = np.tile(y_one_hot, (BATCH_SIZE, 1))\n",
        "    return y_one_hot\n",
        "\n",
        "\n",
        "\n",
        "class ModelContainer():\n",
        "    \"\"\"Encapsulates an Imagenet model, and methods for interacting with it.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name, verbose=True, peace_mask=None, peace_mask_overlay=0.0):\n",
        "        # Peace Mask: None, \"Forward\", \"Backward\"\n",
        "        self.model_name = model_name\n",
        "        self.graph = tf.Graph()\n",
        "        self.sess = tf.Session(graph=self.graph)\n",
        "        self.peace_mask = peace_mask\n",
        "\n",
        "        self.patch_shape = TRACE_PATCH_SHAPE\n",
        "        self._peace_mask_overlay = peace_mask_overlay\n",
        "        self.load_model(verbose=verbose)\n",
        "\n",
        "    def patch(self, new_patch=None):\n",
        "        \"\"\"Retrieve or set the adversarial patch.\n",
        "\n",
        "        new_patch: The new patch to set, or None to get current patch.\n",
        "\n",
        "        Returns: Itself if it set a new patch, or the current patch.\"\"\"\n",
        "        if new_patch is None:\n",
        "            return self._run(self._clipped_patch)\n",
        "\n",
        "        self._run(self._assign_patch, {self._patch_placeholder: new_patch})\n",
        "        return self\n",
        "\n",
        "    def reset_patch(self):\n",
        "        \"\"\"Reset the adversarial patch to all zeros.\"\"\"\n",
        "        self.patch(np.zeros(self.patch_shape))\n",
        "\n",
        "    def train_step(self, data=None, target_ys=None, learning_rate=LEARNING_RATE, scale=None, dropout=None,\n",
        "                   patch_disguise=None, disguise_alpha=None,Target_cls=TARGET_LABEL):\n",
        "        \"\"\"Train the model for one step.\n",
        "\n",
        "        Args:\n",
        "          images: A batch of images to train on, it loads one if not present.\n",
        "          target_ys: Onehot target vector, defaults to TARGET_ONEHOT\n",
        "          learning_rate: Learning rate for this train step.\n",
        "          scale: Either a scalar value for the exact scale, or a (min, max) tuple for the scale range.\n",
        "\n",
        "        Returns: Loss on the target ys.\"\"\"\n",
        "\n",
        "        if data is None:\n",
        "            data,true_label = Trace_loader.get_train_DF_Data(BATCH_SIZE,target_cls=Target_cls)\n",
        "        if target_ys is None:\n",
        "            target_ys = _DF_gen_target_ys(target_cls=Target_cls)\n",
        "        if scale is None:\n",
        "            scale = (1, 7)\n",
        "        feed_dict = {self._Trace_input: np.asarray(data).reshape([BATCH_SIZE,TRACE_LENGTH,1]),\n",
        "                     self._target_ys: target_ys,\n",
        "                     self._learning_rate: learning_rate}\n",
        "\n",
        "        if patch_disguise is not None:\n",
        "            if disguise_alpha is None:\n",
        "                raise ValueError(\"You need disguise_alpha\")\n",
        "            feed_dict[self.patch_disguise] = patch_disguise\n",
        "            feed_dict[self.disguise_alpha] = disguise_alpha\n",
        "        loss, grad, tp,prob,t_vec,pi = self._run([self._loss, self._train_op,self.Trace_patch,self._probabilities,self.transform_vecs,self._patched_input], feed_dict, scale=scale, dropout=dropout)\n",
        "        acc = np.mean(np.equal(np.argmax(prob, 1), np.argmax(true_label, 1)))\n",
        "        target_acc = np.mean(np.equal(np.argmax(prob,1),np.argmax(target_ys,1)))\n",
        "        patch_volume = np.sum(np.abs(tp))\n",
        "        tmp_patch = np.multiply(np.maximum(np.sign(np.multiply(tp, fxx)), 0), tp)\n",
        "        training_model_to_patch = np.ceil(np.minimum(tmp_patch, 0)) + np.floor(np.maximum(tmp_patch, 0))\n",
        "        preprocess_patch_volume = np.sum(np.abs(training_model_to_patch))\n",
        "        data_volume = np.sum(np.abs(data)) / BATCH_SIZE\n",
        "        oh = patch_volume / data_volume\n",
        "        oh_pre = preprocess_patch_volume / data_volume\n",
        "\n",
        "        return loss,acc,target_acc,np.round(oh,decimals=2),np.round(oh_pre,decimals=2)\n",
        "\n",
        "    def inference_batch(self, data=None, target_ys=None, scale=None):\n",
        "        \"\"\"Report loss and label probabilities, and patched images for a batch.\n",
        "\n",
        "        Args:\n",
        "          images: A batch of images to train on, it loads if not present.\n",
        "          target_ys: The target_ys for loss calculation, TARGET_ONEHOT if not present.\"\"\"\n",
        "        labels = []\n",
        "        if data is None:\n",
        "            data,labels = Trace_loader.get_test_DF_Data(BATCH_SIZE, target_cls=TARGET_LABEL)\n",
        "            data = np.array(data).reshape([BATCH_SIZE, TRACE_LENGTH, 1])\n",
        "        if target_ys is None:\n",
        "            target_ys = _DF_gen_target_ys(target_cls=TARGET_LABEL)\n",
        "        feed_dict = {self._Trace_input: data, self._target_ys: target_ys}\n",
        "\n",
        "\n",
        "        loss_per_example, ps, ims,t_vec = self._run([self._loss_per_example, self._probabilities, self._patched_input,self.transform_vecs],\n",
        "                                              feed_dict, scale=scale)\n",
        "        return loss_per_example, ps, ims,data,labels,t_vec\n",
        "\n",
        "    def load_model(self, verbose=True):\n",
        "\n",
        "        keras_mode = False\n",
        "        patch = None\n",
        "        self.DF_INPUT_SHAPE = (TRACE_LENGTH, 1)\n",
        "        self._DF_make_model_and_ops(keras_mode, patch, verbose)\n",
        "\n",
        "    def _run(self, target, feed_dict=None, scale=None, dropout=None):\n",
        "        K.set_session(self.sess)\n",
        "        if feed_dict is None:\n",
        "            feed_dict = {}\n",
        "        feed_dict[self.learning_phase] = False\n",
        "\n",
        "        if scale is not None:\n",
        "            if isinstance(scale, (tuple, list)):\n",
        "                scale_min, scale_max = scale\n",
        "            else:\n",
        "                scale_min, scale_max = (scale, scale)\n",
        "            feed_dict[self.scale_min] = scale_min\n",
        "            feed_dict[self.scale_max] = scale_max\n",
        "\n",
        "        if dropout is not None:\n",
        "            feed_dict[self.dropout] = dropout\n",
        "\n",
        "        return self.sess.run(target, feed_dict=feed_dict)\n",
        "\n",
        "    def _DF_make_model_and_ops(self,  keras_mode, patch_val, verbose):\n",
        "        start = time.time()\n",
        "        K.set_session(self.sess)\n",
        "        with self.sess.graph.as_default():\n",
        "            DF_keras_model = DF_keras_Model(\"DF/models/DF\", self.sess, self.DF_INPUT_SHAPE, DF_NB_CLASSES, TRACE_LENGTH)\n",
        "            M = DF_keras_model.predict\n",
        "            self.learning_phase = K.learning_phase() # if 1 -> train. if 0 -> test. (must be set in test or train time )\n",
        "\n",
        "\n",
        "            Trace_shape = (TRACE_LENGTH,1)\n",
        "            self._Trace_input = keras.layers.Input(shape=Trace_shape) # input (set in test or train time )\n",
        "\n",
        "            self.scale_min = tf.placeholder_with_default(SCALE_MIN, [],name='Scale_min') # ?\n",
        "            self.scale_max = tf.placeholder_with_default(SCALE_MAX, [],name='scale_max') # ?\n",
        "            self._scales = tf.random_uniform([BATCH_SIZE], minval=self.scale_min, maxval=self.scale_max) # ?\n",
        "\n",
        "            Trace_input = self._Trace_input\n",
        "            self.patch_disguise = tf.placeholder_with_default(tf.zeros(self.patch_shape), shape=self.patch_shape,name='patch_disguise') #loss += l2(final_patch and patch_disguise) * disguise_alpha\n",
        "            self.disguise_alpha = tf.placeholder_with_default(0.0, [],name='disguise_alpha')\n",
        "            self.sign_loss_beta = tf.placeholder_with_default(0.0, [], name='disguise_alpha')\n",
        "            self.Trace_patch = tf.Variable(initial_value=tf.zeros(self.patch_shape), dtype=tf.float32,name=\"patch\")\n",
        "            fx = (np.ones(Trace_shape) * -1).astype(np.float32) * -1\n",
        "            fx[::2] *= -1\n",
        "            self.Trace_reverse_patch_acceptable_sign = tf.convert_to_tensor(fx,dtype=tf.float32,name=\"patch_acceptable_sign\")\n",
        "            self._patch_placeholder = tf.placeholder(dtype=tf.float32, shape=self.patch_shape,name='patch_placeholder')\n",
        "            self._assign_patch = tf.assign(self.Trace_patch, self._patch_placeholder) # assign _patch_placeholder to patch\n",
        "            self.zero = tf.zeros(self.patch_shape)\n",
        "\n",
        "\n",
        "\n",
        "            self.modified_patch = self.Trace_patch\n",
        "\n",
        "\n",
        "            def clip_to_valid_image(x):\n",
        "                return tf.clip_by_value(x, clip_value_min=-5000., clip_value_max=5000.) # sure image pixels between -1 and 1\n",
        "\n",
        "            self._clipped_patch = clip_to_valid_image(self.modified_patch) # after making patch, use this variable to get path\n",
        "\n",
        "            self.dropout = tf.placeholder_with_default(1.0, [])\n",
        "            patch_with_dropout = tf.nn.dropout(self.modified_patch, keep_prob=self.dropout)\n",
        "            #patched_input = clip_to_valid_image(self._random_overlay(Trace_input, patch_with_dropout, Trace_shape))\n",
        "            patched_input = clip_to_valid_image(self._Trace_random_overlay(Trace_input, patch_with_dropout, Trace_shape))\n",
        "\n",
        "            # Since this is a return point, we do it before the Keras color shifts\n",
        "            # (but after the resize, so we can see what is really going on)\n",
        "            self._patched_input = patched_input\n",
        "\n",
        "            #if keras_mode:\n",
        "             #   patched_input = to_keras(patched_input)\n",
        "\n",
        "            # Labels for our attack (e.g. always a toaster)\n",
        "            self._target_ys = tf.placeholder(tf.float32, shape=(None, DF_NB_CLASSES),name=\"target_ys\")\n",
        "\n",
        "            #model = M(input_tensor=patched_input)\n",
        "\n",
        "            # Pre-softmax logits of our pretrained model\n",
        "            #logits = model.outputs[0].op.inputs[0]\n",
        "\n",
        "            logits = M(patched_input)\n",
        "\n",
        "            self._loss_per_example = tf.nn.softmax_cross_entropy_with_logits(\n",
        "                labels=self._target_ys,\n",
        "                logits=logits\n",
        "            )\n",
        "            self._target_loss = tf.reduce_mean(self._loss_per_example)\n",
        "\n",
        "            self._patch_loss = tf.nn.l2_loss(self.Trace_patch - self.patch_disguise) * self.disguise_alpha\n",
        "            self.WF_sign_loss = tf.reduce_mean(self.Trace_patch * self.Trace_reverse_patch_acceptable_sign) * self.sign_loss_beta\n",
        "\n",
        "            self._loss = self._target_loss + self._patch_loss + self.WF_sign_loss\n",
        "\n",
        "            # Train our attack by only training on the patch variable\n",
        "            self._learning_rate = tf.placeholder(tf.float32,name='learning_rate')\n",
        "            self._optimizer = tf.train.RMSPropOptimizer(self._learning_rate)\n",
        "            self._train_op = self._optimizer.minimize(self._loss, var_list=[self.Trace_patch])\n",
        "            #self._grad_opt = self._optimizer.compute_gradients(self._loss,var_list=[self.Trace_patch])\n",
        "            #self.mask_sign_and_grad_multiply = tf.multiply(self.Trace_patch_acceptable_sign,tf.math.abs(self._grad_opt[0][1]))\n",
        "            #self.mask_sign_and_grad_add = self.mask_sign_and_grad_multiply + self.Trace_patch\n",
        "            #self.mask_sign_and_grad_positive = tf.maximum(0.,self.mask_sign_and_grad_multiply)\n",
        "            #self.good_grad = tf.multiply(self.mask_sign_and_grad_positive,self._grad_opt)\n",
        "            #self.assign = tf.assign(self.Trace_patch,self.mask_sign_and_grad_add)\n",
        "            #self._train_op = self._optimizer.apply_gradients(self._grad_opt)\n",
        "\n",
        "\n",
        "            self._probabilities = tf.nn.softmax(logits=logits)\n",
        "\n",
        "            if patch_val is not None:\n",
        "                self.patch(patch_val)\n",
        "            else:\n",
        "                self.reset_patch()\n",
        "\n",
        "            elapsed = time.time() - start\n",
        "            if verbose:\n",
        "                print(\"Finished loading {}, took {:.0f}s\".format(self.model_name, elapsed))\n",
        "\n",
        "            self.sess.run(tf.variables_initializer(self._optimizer.variables()))\n",
        "\n",
        "\n",
        "    def _pad_and_tile_patch(self, patch, image_shape):\n",
        "        # Calculate the exact padding\n",
        "        # Image shape req'd because it is sometimes 299 sometimes 224\n",
        "\n",
        "        # padding is the amount of space available on either side of the centered patch\n",
        "        # WARNING: This has been integer-rounded and could be off by one.\n",
        "        #          See _pad_and_tile_patch for usage\n",
        "        return tf.stack([patch] * BATCH_SIZE)\n",
        "\n",
        "\n",
        "    def _Trace_random_overlay(self, Traces, patch, Trace_shape):\n",
        "        \"\"\"Augment images with random rotation, transformation.\n",
        "\n",
        "        Image: BATCHx299x299x3\n",
        "        Patch: 50x50x3\n",
        "\n",
        "        \"\"\"\n",
        "        # Add padding\n",
        "\n",
        "        self.Trace_mask = _line_mask(Trace_shape)\n",
        "\n",
        "        self.Trace_mask = tf.stack([self.Trace_mask] * BATCH_SIZE)\n",
        "        padded_patch = tf.stack([patch] * BATCH_SIZE)\n",
        "\n",
        "        self.transform_vecs = []\n",
        "\n",
        "        def _random_transformation(scale_min, scale_max, Trace):\n",
        "            number_of_burst_in_trace_i = np.count_nonzero(Trace)\n",
        "            start =  np.round(np.random.randint(low=0,high=np.maximum(1,number_of_burst_in_trace_i)))\n",
        "            if(Trace[start,0] < 0):\n",
        "                start += 1\n",
        "            return np.array([start]).astype(np.float32)\n",
        "\n",
        "        for i in range(BATCH_SIZE):\n",
        "            # Shift and scale the patch for each image in the batch\n",
        "            random_xform_vector = tf.py_func(_random_transformation, [self.scale_min, self.scale_max, Traces[i]],\n",
        "                                             tf.float32)\n",
        "            random_xform_vector.set_shape([1])\n",
        "\n",
        "            self.transform_vecs.append(random_xform_vector)\n",
        "        self.transform_vecs = tf.stack(self.transform_vecs)\n",
        "\n",
        "\n",
        "\n",
        "        self.Trace_mask_scaled = []\n",
        "        for i in range(BATCH_SIZE):\n",
        "            # Shift and scale the patch for each image in the batch\n",
        "            Trace_mask_vector = tf.roll(self.Trace_mask[i], tf.to_int32(self.transform_vecs[i][0]),axis=0)\n",
        "\n",
        "            Trace_mask_vector.set_shape([TRACE_LENGTH,1])\n",
        "\n",
        "            self.Trace_mask_scaled.append(Trace_mask_vector)\n",
        "        self.Trace_mask_scaled = tf.stack(self.Trace_mask_scaled)\n",
        "\n",
        "\n",
        "\n",
        "        self.padded_patch_scaled = []\n",
        "        for i in range(BATCH_SIZE):\n",
        "            # Shift and scale the patch for each image in the batch\n",
        "            padded_patch_vector = tf.roll(padded_patch[i], tf.to_int32(self.transform_vecs[i][0]), axis=0)\n",
        "            padded_patch_vector.set_shape([TRACE_LENGTH,1])\n",
        "\n",
        "            self.padded_patch_scaled.append(padded_patch_vector)\n",
        "        self.padded_patch_scaled = tf.stack(self.padded_patch_scaled)\n",
        "\n",
        "        self.inverted_mask = (1 - self.Trace_mask_scaled)\n",
        "\n",
        "        #return Traces * self.inverted_mask + self.padded_patch_scaled * self.Trace_mask_scaled\n",
        "        return Traces + self.padded_patch_scaled * self.Trace_mask_scaled\n",
        "\n",
        "def train_patch(model_targets_name=None,Num_of_Patch=1,Target_cls=TARGET_LABEL,Train_Steps=100):\n",
        "    x = 0\n",
        "    training_model_to_patch = {}\n",
        "    for m in model_targets_name:\n",
        "        print(\"Training %s\" % m)\n",
        "        M = MM.nc[m]\n",
        "        for j in range(Num_of_Patch):\n",
        "            if Target_cls == None:\n",
        "                Target_claas = j\n",
        "            print(\"Training class \",Target_claas)\n",
        "            M.reset_patch()\n",
        "            for i in range(Train_Steps):\n",
        "                x += 1\n",
        "                loss,acc,target_acc,boh,ppboh = M.train_step(scale=(1, 10),Target_cls=Target_claas)\n",
        "                if i % int(Train_Steps / Train_Steps) == 0:\n",
        "                    print(\"[%s] loss: %s acc: %s targeted_attack_success: %s ----- OH: %s PPOH: %s\" % (i, loss,acc*100,target_acc*100,boh,ppboh))\n",
        "            tmp_patch = np.multiply(np.maximum(np.sign(np.multiply(M.patch(),fxx)),0),M.patch())\n",
        "            training_model_to_patch[j] = np.ceil(np.minimum(tmp_patch,0)) + np.floor(np.maximum(tmp_patch,0))\n",
        "            #regular_training_model_to_patch[j] = M.patch()\n",
        "        print(\"PatchLength: \", TRACE_MASK_LENGTH, \" Steps:\", Train_Steps, \" LR: \", LEARNING_RATE)\n",
        "    return training_model_to_patch\n",
        "\n",
        "def Make_DF_Report(MC=None,Patchs=None,Target_cls=None):\n",
        "    m = MC.nc['DF']\n",
        "    for i in range(len(Patchs)):\n",
        "        m.patch(Patchs[i])\n",
        "        patch_oh = np.sum(np.abs(Patchs[i]))\n",
        "        if Target_cls == None:\n",
        "            Target_class = i\n",
        "        DF_report(m, n=512, show_images=0, scale=5,BATCH_SIZE=BATCH_SIZE,TARGET_LABEL=Target_class,patch_oh=patch_oh)\n",
        "######################@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@##############################3\n",
        "\n",
        "\n",
        "\n",
        "Trace_loader = DFDataLoader(DF_NB_CLASSES)\n",
        "\n",
        "print(\"Creating MetaModel...\")\n",
        "MM = MetaModel(ModelContainer = ModelContainer,MODEL_NAMES = MODEL_NAMES,PATCH_SHAPE=TRACE_PATCH_SHAPE)\n",
        "model_targets = MODEL_NAMES\n",
        "load_flag = 0\n",
        "train_flag = 1\n",
        "STEPS = 50\n",
        "fxx = (np.ones([TRACE_LENGTH, 1]) * -1).astype(np.float32)\n",
        "fxx[::2] *= -1\n",
        "regular_training_model_to_patch = {}\n",
        "if os.path.exists(osp.join(DATA_DIR, \"regular_training_model_to_patch\")) and load_flag == 1:\n",
        "    regular_training_model_to_patch = load_obj(\"DF_regular_training_model_to_patch\")\n",
        "else:\n",
        "    regular_training_model_to_patch = train_patch(model_targets_name=MODEL_NAMES,Num_of_Patch=95,Target_cls=None,Train_Steps=STEPS)\n",
        "    save_obj(regular_training_model_to_patch, \"DF_regular_training_model_to_patch\")\n",
        "\n",
        "report_flag=1\n",
        "if report_flag:\n",
        "    Make_DF_Report(MC=MM,Patchs=regular_training_model_to_patch)\n",
        "AdvTrainingData_flag = 1\n",
        "AdvData = {}\n",
        "if AdvTrainingData_flag:\n",
        "    AdvTrainingData_train,AdvTrainingLabel_train = make_adversarial_training_data(patchs=regular_training_model_to_patch,data=Trace_loader.DF_data.train_data,labels=Trace_loader.DF_data.train_labels,BATCH_SIZE=BATCH_SIZE,MC=MM,scale=5,save=1,data_type='Train1')\n",
        "    AdvTrainingData_valid,AdvTrainingLabel_valid = make_adversarial_training_data(patchs=regular_training_model_to_patch,data=Trace_loader.DF_data.validation_data,labels=Trace_loader.DF_data.validation_labels,BATCH_SIZE=BATCH_SIZE,MC=MM,scale=5,save=1,data_type='Valid1')\n",
        "    Trace_loader.DF_data.train_data = AdvTrainingData_train\n",
        "    Trace_loader.DF_data.train_labels = AdvTrainingLabel_train\n",
        "    Trace_loader.DF_data.validation_data = AdvTrainingData_valid\n",
        "    Trace_loader.DF_data.validation_labels = AdvTrainingLabel_valid\n",
        "else:\n",
        "    print('LoadAdvData')\n",
        "    Trace_loader.DF_data.train_data = np.load('AdvTrainingData_Train1.npz')['arr_0']\n",
        "    Trace_loader.DF_data.train_labels = np.load('AdvTrainingLabel_Train1.npz')['arr_0']\n",
        "    Trace_loader.DF_data.validation_data = np.load('AdvTrainingData_Valid1.npz')['arr_0']\n",
        "    Trace_loader.DF_data.validation_labels = np.load('AdvTrainingLabel_Valid1.npz')['arr_0']\n",
        "\n",
        "\n",
        "if not os.path.isdir('models'):\n",
        "    os.makedirs('models')\n",
        "m = MM.nc['DF']\n",
        "with m.sess.graph.as_default():   \n",
        "  train(Trace_loader.DF_data, \"models/DF\",input_shape=INPUT_SHAPE, classes=DF_NB_CLASSES, num_epochs=10)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['DF']\n",
            "Loading non-defended dataset for closed-world scenario\n",
            "train\n",
            "valid\n",
            "test\n",
            "Data dimensions:\n",
            "X: Training data's shape :  (76000, 5000, 1)\n",
            "y: Training data's shape :  (76000, 95)\n",
            "X: Validation data's shape :  (9500, 5000, 1)\n",
            "y: Validation data's shape :  (9500, 95)\n",
            "X: Testing data's shape :  (9500, 5000, 1)\n",
            "y: Testing data's shape :  (9500, 95)\n",
            "Creating MetaModel...\n",
            "WARNING:tensorflow:From <ipython-input-3-c66c696e5876>:282: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Finished loading DF, took 8s\n",
            "Training DF\n",
            "Training class  0\n",
            "[0] loss: 20.04905 acc: 93.75 targeted_attack_success: 0.0 ----- OH: 0.0 PPOH: 0.0\n",
            "[1] loss: 15.566647 acc: 84.375 targeted_attack_success: 0.0 ----- OH: 0.03 PPOH: 0.0\n",
            "[2] loss: 13.5111685 acc: 45.3125 targeted_attack_success: 0.0 ----- OH: 0.09 PPOH: 0.05\n",
            "[3] loss: 14.830189 acc: 40.625 targeted_attack_success: 0.0 ----- OH: 0.09 PPOH: 0.05\n",
            "[4] loss: 12.482303 acc: 29.6875 targeted_attack_success: 0.0 ----- OH: 0.13 PPOH: 0.07\n",
            "[5] loss: 12.507452 acc: 37.5 targeted_attack_success: 0.0 ----- OH: 0.12 PPOH: 0.06\n",
            "[6] loss: 14.16032 acc: 46.875 targeted_attack_success: 0.0 ----- OH: 0.11 PPOH: 0.06\n",
            "[7] loss: 12.929182 acc: 37.5 targeted_attack_success: 0.0 ----- OH: 0.13 PPOH: 0.07\n",
            "[8] loss: 11.742891 acc: 25.0 targeted_attack_success: 0.0 ----- OH: 0.15 PPOH: 0.08\n",
            "[9] loss: 11.986906 acc: 42.1875 targeted_attack_success: 0.0 ----- OH: 0.15 PPOH: 0.08\n",
            "[10] loss: 14.141239 acc: 43.75 targeted_attack_success: 0.0 ----- OH: 0.13 PPOH: 0.07\n",
            "[11] loss: 13.61473 acc: 34.375 targeted_attack_success: 0.0 ----- OH: 0.14 PPOH: 0.07\n",
            "[12] loss: 12.143349 acc: 40.625 targeted_attack_success: 0.0 ----- OH: 0.14 PPOH: 0.07\n",
            "[13] loss: 11.8917055 acc: 31.25 targeted_attack_success: 0.0 ----- OH: 0.15 PPOH: 0.08\n",
            "[14] loss: 12.934574 acc: 48.4375 targeted_attack_success: 0.0 ----- OH: 0.13 PPOH: 0.07\n",
            "[15] loss: 11.845123 acc: 25.0 targeted_attack_success: 0.0 ----- OH: 0.17 PPOH: 0.09\n",
            "[16] loss: 13.199444 acc: 34.375 targeted_attack_success: 0.0 ----- OH: 0.14 PPOH: 0.07\n",
            "[17] loss: 12.00531 acc: 21.875 targeted_attack_success: 0.0 ----- OH: 0.17 PPOH: 0.08\n",
            "[18] loss: 11.612825 acc: 31.25 targeted_attack_success: 0.0 ----- OH: 0.19 PPOH: 0.09\n",
            "[19] loss: 12.664829 acc: 43.75 targeted_attack_success: 0.0 ----- OH: 0.15 PPOH: 0.07\n",
            "[20] loss: 13.029533 acc: 31.25 targeted_attack_success: 0.0 ----- OH: 0.17 PPOH: 0.08\n",
            "[21] loss: 10.859906 acc: 26.5625 targeted_attack_success: 0.0 ----- OH: 0.27 PPOH: 0.13\n",
            "[22] loss: 14.069071 acc: 35.9375 targeted_attack_success: 0.0 ----- OH: 0.16 PPOH: 0.07\n",
            "[23] loss: 12.551438 acc: 42.1875 targeted_attack_success: 0.0 ----- OH: 0.19 PPOH: 0.08\n",
            "[24] loss: 11.22213 acc: 26.5625 targeted_attack_success: 0.0 ----- OH: 0.25 PPOH: 0.11\n",
            "[25] loss: 12.264846 acc: 29.6875 targeted_attack_success: 0.0 ----- OH: 0.21 PPOH: 0.09\n",
            "[26] loss: 11.796308 acc: 25.0 targeted_attack_success: 0.0 ----- OH: 0.2 PPOH: 0.08\n",
            "[27] loss: 10.973858 acc: 23.4375 targeted_attack_success: 0.0 ----- OH: 0.21 PPOH: 0.09\n",
            "[28] loss: 11.877036 acc: 35.9375 targeted_attack_success: 0.0 ----- OH: 0.23 PPOH: 0.09\n",
            "[29] loss: 11.866917 acc: 28.125 targeted_attack_success: 0.0 ----- OH: 0.21 PPOH: 0.09\n",
            "[30] loss: 12.869934 acc: 37.5 targeted_attack_success: 0.0 ----- OH: 0.18 PPOH: 0.07\n",
            "[31] loss: 10.1018505 acc: 29.6875 targeted_attack_success: 0.0 ----- OH: 0.29 PPOH: 0.11\n",
            "[32] loss: 11.415387 acc: 20.3125 targeted_attack_success: 0.0 ----- OH: 0.25 PPOH: 0.1\n",
            "[33] loss: 11.715752 acc: 28.125 targeted_attack_success: 0.0 ----- OH: 0.19 PPOH: 0.07\n",
            "[34] loss: 11.302213 acc: 35.9375 targeted_attack_success: 0.0 ----- OH: 0.23 PPOH: 0.09\n",
            "[35] loss: 10.737888 acc: 25.0 targeted_attack_success: 0.0 ----- OH: 0.25 PPOH: 0.09\n",
            "[36] loss: 10.943096 acc: 32.8125 targeted_attack_success: 0.0 ----- OH: 0.22 PPOH: 0.08\n",
            "[37] loss: 10.272701 acc: 26.5625 targeted_attack_success: 0.0 ----- OH: 0.23 PPOH: 0.08\n",
            "[38] loss: 10.814236 acc: 25.0 targeted_attack_success: 0.0 ----- OH: 0.25 PPOH: 0.08\n",
            "[39] loss: 10.223838 acc: 25.0 targeted_attack_success: 0.0 ----- OH: 0.26 PPOH: 0.09\n",
            "[40] loss: 10.112905 acc: 28.125 targeted_attack_success: 0.0 ----- OH: 0.26 PPOH: 0.09\n",
            "[41] loss: 10.998149 acc: 32.8125 targeted_attack_success: 0.0 ----- OH: 0.24 PPOH: 0.08\n",
            "[42] loss: 10.379127 acc: 29.6875 targeted_attack_success: 0.0 ----- OH: 0.26 PPOH: 0.09\n",
            "[43] loss: 10.521342 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 0.24 PPOH: 0.08\n",
            "[44] loss: 10.361956 acc: 20.3125 targeted_attack_success: 0.0 ----- OH: 0.29 PPOH: 0.09\n",
            "[45] loss: 11.164598 acc: 40.625 targeted_attack_success: 0.0 ----- OH: 0.25 PPOH: 0.07\n",
            "[46] loss: 10.691422 acc: 28.125 targeted_attack_success: 0.0 ----- OH: 0.24 PPOH: 0.08\n",
            "[47] loss: 11.264659 acc: 37.5 targeted_attack_success: 0.0 ----- OH: 0.25 PPOH: 0.08\n",
            "[48] loss: 9.744365 acc: 29.6875 targeted_attack_success: 0.0 ----- OH: 0.27 PPOH: 0.08\n",
            "[49] loss: 9.476728 acc: 23.4375 targeted_attack_success: 0.0 ----- OH: 0.26 PPOH: 0.09\n",
            "Training class  1\n",
            "[0] loss: 20.659931 acc: 98.4375 targeted_attack_success: 0.0 ----- OH: 0.0 PPOH: 0.0\n",
            "[1] loss: 13.013368 acc: 28.125 targeted_attack_success: 0.0 ----- OH: 0.33 PPOH: 0.1\n",
            "[2] loss: 12.057354 acc: 20.3125 targeted_attack_success: 0.0 ----- OH: 0.34 PPOH: 0.09\n",
            "[3] loss: 11.522316 acc: 31.25 targeted_attack_success: 0.0 ----- OH: 0.37 PPOH: 0.08\n",
            "[4] loss: 11.303989 acc: 29.6875 targeted_attack_success: 0.0 ----- OH: 0.39 PPOH: 0.09\n",
            "[5] loss: 9.99681 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 0.35 PPOH: 0.09\n",
            "[6] loss: 10.820332 acc: 23.4375 targeted_attack_success: 0.0 ----- OH: 0.42 PPOH: 0.12\n",
            "[7] loss: 10.993322 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 0.39 PPOH: 0.12\n",
            "[8] loss: 10.569729 acc: 18.75 targeted_attack_success: 0.0 ----- OH: 0.46 PPOH: 0.15\n",
            "[9] loss: 10.240456 acc: 21.875 targeted_attack_success: 0.0 ----- OH: 0.48 PPOH: 0.15\n",
            "[10] loss: 12.138292 acc: 35.9375 targeted_attack_success: 0.0 ----- OH: 0.44 PPOH: 0.14\n",
            "[11] loss: 9.886994 acc: 14.0625 targeted_attack_success: 0.0 ----- OH: 0.45 PPOH: 0.15\n",
            "[12] loss: 10.615855 acc: 18.75 targeted_attack_success: 0.0 ----- OH: 0.46 PPOH: 0.14\n",
            "[13] loss: 11.504328 acc: 26.5625 targeted_attack_success: 0.0 ----- OH: 0.42 PPOH: 0.13\n",
            "[14] loss: 9.492944 acc: 18.75 targeted_attack_success: 0.0 ----- OH: 0.6 PPOH: 0.2\n",
            "[15] loss: 9.884195 acc: 15.625 targeted_attack_success: 0.0 ----- OH: 0.47 PPOH: 0.17\n",
            "[16] loss: 10.107019 acc: 21.875 targeted_attack_success: 0.0 ----- OH: 0.49 PPOH: 0.16\n",
            "[17] loss: 9.46825 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 0.56 PPOH: 0.2\n",
            "[18] loss: 10.595575 acc: 23.4375 targeted_attack_success: 0.0 ----- OH: 0.48 PPOH: 0.17\n",
            "[19] loss: 9.632831 acc: 7.8125 targeted_attack_success: 0.0 ----- OH: 0.66 PPOH: 0.26\n",
            "[20] loss: 9.849594 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 0.53 PPOH: 0.2\n",
            "[21] loss: 9.731247 acc: 12.5 targeted_attack_success: 0.0 ----- OH: 0.57 PPOH: 0.22\n",
            "[22] loss: 10.519464 acc: 20.3125 targeted_attack_success: 0.0 ----- OH: 0.57 PPOH: 0.22\n",
            "[23] loss: 9.571113 acc: 12.5 targeted_attack_success: 0.0 ----- OH: 0.65 PPOH: 0.26\n",
            "[24] loss: 10.380447 acc: 25.0 targeted_attack_success: 0.0 ----- OH: 0.56 PPOH: 0.22\n",
            "[25] loss: 8.931905 acc: 18.75 targeted_attack_success: 0.0 ----- OH: 0.64 PPOH: 0.25\n",
            "[26] loss: 10.520117 acc: 26.5625 targeted_attack_success: 0.0 ----- OH: 0.57 PPOH: 0.24\n",
            "[27] loss: 10.049088 acc: 14.0625 targeted_attack_success: 0.0 ----- OH: 0.69 PPOH: 0.28\n",
            "[28] loss: 9.964548 acc: 12.5 targeted_attack_success: 0.0 ----- OH: 0.77 PPOH: 0.34\n",
            "[29] loss: 9.816481 acc: 10.9375 targeted_attack_success: 0.0 ----- OH: 0.66 PPOH: 0.28\n",
            "[30] loss: 10.179176 acc: 14.0625 targeted_attack_success: 0.0 ----- OH: 0.73 PPOH: 0.32\n",
            "[31] loss: 9.530024 acc: 10.9375 targeted_attack_success: 0.0 ----- OH: 0.84 PPOH: 0.38\n",
            "[32] loss: 10.483635 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 0.67 PPOH: 0.29\n",
            "[33] loss: 9.953923 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 0.73 PPOH: 0.3\n",
            "[34] loss: 9.841402 acc: 12.5 targeted_attack_success: 0.0 ----- OH: 0.79 PPOH: 0.34\n",
            "[35] loss: 9.992761 acc: 6.25 targeted_attack_success: 0.0 ----- OH: 0.89 PPOH: 0.39\n",
            "[36] loss: 10.03792 acc: 20.3125 targeted_attack_success: 0.0 ----- OH: 0.77 PPOH: 0.35\n",
            "[37] loss: 9.8401985 acc: 9.375 targeted_attack_success: 0.0 ----- OH: 0.84 PPOH: 0.37\n",
            "[38] loss: 10.245628 acc: 15.625 targeted_attack_success: 0.0 ----- OH: 0.79 PPOH: 0.36\n",
            "[39] loss: 10.118277 acc: 7.8125 targeted_attack_success: 0.0 ----- OH: 0.91 PPOH: 0.44\n",
            "[40] loss: 9.470736 acc: 12.5 targeted_attack_success: 0.0 ----- OH: 0.85 PPOH: 0.37\n",
            "[41] loss: 11.591982 acc: 12.5 targeted_attack_success: 0.0 ----- OH: 0.91 PPOH: 0.4\n",
            "[42] loss: 9.952565 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 0.87 PPOH: 0.42\n",
            "[43] loss: 10.103449 acc: 10.9375 targeted_attack_success: 0.0 ----- OH: 0.91 PPOH: 0.46\n",
            "[44] loss: 10.337088 acc: 20.3125 targeted_attack_success: 0.0 ----- OH: 0.95 PPOH: 0.49\n",
            "[45] loss: 9.843434 acc: 14.0625 targeted_attack_success: 0.0 ----- OH: 1.09 PPOH: 0.51\n",
            "[46] loss: 10.190126 acc: 10.9375 targeted_attack_success: 0.0 ----- OH: 0.92 PPOH: 0.43\n",
            "[47] loss: 9.6424465 acc: 20.3125 targeted_attack_success: 0.0 ----- OH: 1.1 PPOH: 0.51\n",
            "[48] loss: 10.727483 acc: 4.6875 targeted_attack_success: 0.0 ----- OH: 1.44 PPOH: 0.68\n",
            "[49] loss: 10.689056 acc: 10.9375 targeted_attack_success: 0.0 ----- OH: 1.22 PPOH: 0.57\n",
            "Training class  2\n",
            "[0] loss: 20.280823 acc: 100.0 targeted_attack_success: 0.0 ----- OH: 0.0 PPOH: 0.0\n",
            "[1] loss: 28.964626 acc: 4.6875 targeted_attack_success: 0.0 ----- OH: 2.02 PPOH: 0.71\n",
            "[2] loss: 18.55629 acc: 3.125 targeted_attack_success: 0.0 ----- OH: 1.91 PPOH: 0.57\n",
            "[3] loss: 11.903685 acc: 14.0625 targeted_attack_success: 0.0 ----- OH: 1.11 PPOH: 0.32\n",
            "[4] loss: 9.588589 acc: 10.9375 targeted_attack_success: 0.0 ----- OH: 1.08 PPOH: 0.24\n",
            "[5] loss: 9.963543 acc: 14.0625 targeted_attack_success: 0.0 ----- OH: 0.88 PPOH: 0.21\n",
            "[6] loss: 9.77798 acc: 14.0625 targeted_attack_success: 0.0 ----- OH: 0.91 PPOH: 0.19\n",
            "[7] loss: 11.838026 acc: 9.375 targeted_attack_success: 0.0 ----- OH: 0.85 PPOH: 0.2\n",
            "[8] loss: 9.375561 acc: 10.9375 targeted_attack_success: 0.0 ----- OH: 1.07 PPOH: 0.3\n",
            "[9] loss: 11.725138 acc: 28.125 targeted_attack_success: 0.0 ----- OH: 0.87 PPOH: 0.2\n",
            "[10] loss: 11.299896 acc: 10.9375 targeted_attack_success: 0.0 ----- OH: 0.96 PPOH: 0.28\n",
            "[11] loss: 8.812193 acc: 10.9375 targeted_attack_success: 0.0 ----- OH: 0.82 PPOH: 0.26\n",
            "[12] loss: 9.720543 acc: 12.5 targeted_attack_success: 0.0 ----- OH: 0.88 PPOH: 0.24\n",
            "[13] loss: 9.800358 acc: 10.9375 targeted_attack_success: 0.0 ----- OH: 0.99 PPOH: 0.37\n",
            "[14] loss: 7.8860927 acc: 3.125 targeted_attack_success: 1.5625 ----- OH: 0.96 PPOH: 0.3\n",
            "[15] loss: 8.171682 acc: 21.875 targeted_attack_success: 1.5625 ----- OH: 0.96 PPOH: 0.32\n",
            "[16] loss: 13.379816 acc: 1.5625 targeted_attack_success: 0.0 ----- OH: 1.2 PPOH: 0.48\n",
            "[17] loss: 15.9976425 acc: 4.6875 targeted_attack_success: 0.0 ----- OH: 1.07 PPOH: 0.51\n",
            "[18] loss: 12.07794 acc: 4.6875 targeted_attack_success: 0.0 ----- OH: 1.46 PPOH: 0.62\n",
            "[19] loss: 11.175144 acc: 15.625 targeted_attack_success: 0.0 ----- OH: 1.32 PPOH: 0.51\n",
            "[20] loss: 9.202051 acc: 15.625 targeted_attack_success: 0.0 ----- OH: 1.17 PPOH: 0.46\n",
            "[21] loss: 8.379618 acc: 12.5 targeted_attack_success: 0.0 ----- OH: 1.19 PPOH: 0.45\n",
            "[22] loss: 7.995288 acc: 20.3125 targeted_attack_success: 9.375 ----- OH: 1.28 PPOH: 0.55\n",
            "[23] loss: 9.873791 acc: 7.8125 targeted_attack_success: 4.6875 ----- OH: 1.33 PPOH: 0.61\n",
            "[24] loss: 7.462538 acc: 15.625 targeted_attack_success: 3.125 ----- OH: 1.96 PPOH: 0.89\n",
            "[25] loss: 6.984462 acc: 12.5 targeted_attack_success: 26.5625 ----- OH: 1.8 PPOH: 0.86\n",
            "[26] loss: 6.647496 acc: 12.5 targeted_attack_success: 17.1875 ----- OH: 1.82 PPOH: 0.84\n",
            "[27] loss: 6.314522 acc: 10.9375 targeted_attack_success: 23.4375 ----- OH: 1.81 PPOH: 0.84\n",
            "[28] loss: 5.8395476 acc: 14.0625 targeted_attack_success: 17.1875 ----- OH: 1.92 PPOH: 0.88\n",
            "[29] loss: 6.3036156 acc: 9.375 targeted_attack_success: 18.75 ----- OH: 1.68 PPOH: 0.77\n",
            "[30] loss: 4.997794 acc: 15.625 targeted_attack_success: 31.25 ----- OH: 1.81 PPOH: 0.82\n",
            "[31] loss: 4.6297235 acc: 7.8125 targeted_attack_success: 35.9375 ----- OH: 2.17 PPOH: 0.99\n",
            "[32] loss: 6.766618 acc: 15.625 targeted_attack_success: 25.0 ----- OH: 1.79 PPOH: 0.82\n",
            "[33] loss: 8.155029 acc: 9.375 targeted_attack_success: 6.25 ----- OH: 1.96 PPOH: 0.95\n",
            "[34] loss: 8.873826 acc: 10.9375 targeted_attack_success: 4.6875 ----- OH: 2.71 PPOH: 1.27\n",
            "[35] loss: 4.9226255 acc: 7.8125 targeted_attack_success: 7.8125 ----- OH: 2.52 PPOH: 1.17\n",
            "[36] loss: 6.220599 acc: 6.25 targeted_attack_success: 26.5625 ----- OH: 2.02 PPOH: 0.95\n",
            "[37] loss: 6.6432867 acc: 12.5 targeted_attack_success: 31.25 ----- OH: 2.28 PPOH: 1.04\n",
            "[38] loss: 5.33361 acc: 4.6875 targeted_attack_success: 20.3125 ----- OH: 2.61 PPOH: 1.24\n",
            "[39] loss: 6.014023 acc: 18.75 targeted_attack_success: 28.125 ----- OH: 2.8 PPOH: 1.32\n",
            "[40] loss: 5.1669946 acc: 9.375 targeted_attack_success: 10.9375 ----- OH: 2.95 PPOH: 1.47\n",
            "[41] loss: 4.6450567 acc: 10.9375 targeted_attack_success: 43.75 ----- OH: 2.41 PPOH: 1.19\n",
            "[42] loss: 4.0321274 acc: 0.0 targeted_attack_success: 35.9375 ----- OH: 3.1 PPOH: 1.55\n",
            "[43] loss: 3.6249967 acc: 7.8125 targeted_attack_success: 29.6875 ----- OH: 2.73 PPOH: 1.36\n",
            "[44] loss: 6.122076 acc: 4.6875 targeted_attack_success: 14.0625 ----- OH: 2.4 PPOH: 1.19\n",
            "[45] loss: 5.995801 acc: 14.0625 targeted_attack_success: 28.125 ----- OH: 2.73 PPOH: 1.34\n",
            "[46] loss: 9.812113 acc: 12.5 targeted_attack_success: 4.6875 ----- OH: 2.31 PPOH: 1.15\n",
            "[47] loss: 7.399622 acc: 9.375 targeted_attack_success: 17.1875 ----- OH: 2.67 PPOH: 1.35\n",
            "[48] loss: 5.2833357 acc: 6.25 targeted_attack_success: 17.1875 ----- OH: 3.36 PPOH: 1.78\n",
            "[49] loss: 5.564497 acc: 4.6875 targeted_attack_success: 35.9375 ----- OH: 3.21 PPOH: 1.66\n",
            "Training class  3\n",
            "[0] loss: 20.116236 acc: 96.875 targeted_attack_success: 0.0 ----- OH: 0.0 PPOH: 0.0\n",
            "[1] loss: 36.7125 acc: 1.5625 targeted_attack_success: 0.0 ----- OH: 2.33 PPOH: 1.16\n",
            "[2] loss: 22.75334 acc: 4.6875 targeted_attack_success: 0.0 ----- OH: 2.06 PPOH: 0.95\n",
            "[3] loss: 13.4071045 acc: 1.5625 targeted_attack_success: 0.0 ----- OH: 2.0 PPOH: 1.1\n",
            "[4] loss: 10.053513 acc: 9.375 targeted_attack_success: 0.0 ----- OH: 1.49 PPOH: 0.88\n",
            "[5] loss: 7.918662 acc: 7.8125 targeted_attack_success: 3.125 ----- OH: 1.64 PPOH: 1.01\n",
            "[6] loss: 8.712028 acc: 6.25 targeted_attack_success: 0.0 ----- OH: 1.38 PPOH: 0.82\n",
            "[7] loss: 16.640345 acc: 3.125 targeted_attack_success: 0.0 ----- OH: 1.58 PPOH: 0.98\n",
            "[8] loss: 7.415019 acc: 9.375 targeted_attack_success: 4.6875 ----- OH: 1.49 PPOH: 0.87\n",
            "[9] loss: 8.871165 acc: 10.9375 targeted_attack_success: 7.8125 ----- OH: 1.5 PPOH: 0.9\n",
            "[10] loss: 9.669647 acc: 4.6875 targeted_attack_success: 0.0 ----- OH: 1.69 PPOH: 1.04\n",
            "[11] loss: 14.803825 acc: 1.5625 targeted_attack_success: 0.0 ----- OH: 1.95 PPOH: 1.13\n",
            "[12] loss: 7.769491 acc: 7.8125 targeted_attack_success: 3.125 ----- OH: 2.08 PPOH: 1.28\n",
            "[13] loss: 8.857478 acc: 4.6875 targeted_attack_success: 0.0 ----- OH: 1.92 PPOH: 1.11\n",
            "[14] loss: 10.573242 acc: 4.6875 targeted_attack_success: 7.8125 ----- OH: 1.96 PPOH: 1.16\n",
            "[15] loss: 11.027899 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 1.74 PPOH: 1.05\n",
            "[16] loss: 9.441502 acc: 4.6875 targeted_attack_success: 9.375 ----- OH: 2.16 PPOH: 1.28\n",
            "[17] loss: 5.3225155 acc: 4.6875 targeted_attack_success: 35.9375 ----- OH: 1.78 PPOH: 1.06\n",
            "[18] loss: 7.745104 acc: 4.6875 targeted_attack_success: 15.625 ----- OH: 2.1 PPOH: 1.19\n",
            "[19] loss: 6.642585 acc: 3.125 targeted_attack_success: 54.6875 ----- OH: 2.23 PPOH: 1.32\n",
            "[20] loss: 7.6305265 acc: 10.9375 targeted_attack_success: 6.25 ----- OH: 2.16 PPOH: 1.26\n",
            "[21] loss: 12.150054 acc: 4.6875 targeted_attack_success: 4.6875 ----- OH: 2.05 PPOH: 1.23\n",
            "[22] loss: 6.995961 acc: 10.9375 targeted_attack_success: 1.5625 ----- OH: 2.22 PPOH: 1.29\n",
            "[23] loss: 6.819458 acc: 3.125 targeted_attack_success: 21.875 ----- OH: 2.22 PPOH: 1.3\n",
            "[24] loss: 7.0564623 acc: 14.0625 targeted_attack_success: 34.375 ----- OH: 1.66 PPOH: 1.0\n",
            "[25] loss: 5.8915553 acc: 4.6875 targeted_attack_success: 34.375 ----- OH: 2.6 PPOH: 1.53\n",
            "[26] loss: 4.380082 acc: 1.5625 targeted_attack_success: 7.8125 ----- OH: 2.49 PPOH: 1.51\n",
            "[27] loss: 6.4739494 acc: 3.125 targeted_attack_success: 42.1875 ----- OH: 2.25 PPOH: 1.33\n",
            "[28] loss: 8.712164 acc: 4.6875 targeted_attack_success: 3.125 ----- OH: 2.1 PPOH: 1.24\n",
            "[29] loss: 4.540286 acc: 3.125 targeted_attack_success: 64.0625 ----- OH: 2.37 PPOH: 1.44\n",
            "[30] loss: 5.962211 acc: 7.8125 targeted_attack_success: 48.4375 ----- OH: 2.4 PPOH: 1.44\n",
            "[31] loss: 6.135582 acc: 9.375 targeted_attack_success: 46.875 ----- OH: 2.0 PPOH: 1.15\n",
            "[32] loss: 6.890454 acc: 10.9375 targeted_attack_success: 31.25 ----- OH: 1.89 PPOH: 1.1\n",
            "[33] loss: 6.8406787 acc: 9.375 targeted_attack_success: 37.5 ----- OH: 2.07 PPOH: 1.18\n",
            "[34] loss: 6.8974743 acc: 15.625 targeted_attack_success: 12.5 ----- OH: 1.88 PPOH: 1.11\n",
            "[35] loss: 4.5000744 acc: 3.125 targeted_attack_success: 64.0625 ----- OH: 2.43 PPOH: 1.44\n",
            "[36] loss: 3.571041 acc: 3.125 targeted_attack_success: 60.9375 ----- OH: 2.23 PPOH: 1.31\n",
            "[37] loss: 5.3541183 acc: 3.125 targeted_attack_success: 46.875 ----- OH: 2.2 PPOH: 1.25\n",
            "[38] loss: 8.179278 acc: 10.9375 targeted_attack_success: 4.6875 ----- OH: 1.87 PPOH: 1.03\n",
            "[39] loss: 7.480588 acc: 7.8125 targeted_attack_success: 42.1875 ----- OH: 1.76 PPOH: 1.03\n",
            "[40] loss: 8.714024 acc: 6.25 targeted_attack_success: 0.0 ----- OH: 2.65 PPOH: 1.53\n",
            "[41] loss: 11.38245 acc: 6.25 targeted_attack_success: 6.25 ----- OH: 2.15 PPOH: 1.18\n",
            "[42] loss: 4.4879904 acc: 6.25 targeted_attack_success: 50.0 ----- OH: 2.68 PPOH: 1.5\n",
            "[43] loss: 6.5188003 acc: 3.125 targeted_attack_success: 32.8125 ----- OH: 2.52 PPOH: 1.4\n",
            "[44] loss: 8.320759 acc: 1.5625 targeted_attack_success: 17.1875 ----- OH: 2.71 PPOH: 1.54\n",
            "[45] loss: 5.1397614 acc: 7.8125 targeted_attack_success: 32.8125 ----- OH: 2.91 PPOH: 1.67\n",
            "[46] loss: 7.3165274 acc: 4.6875 targeted_attack_success: 39.0625 ----- OH: 2.42 PPOH: 1.39\n",
            "[47] loss: 12.152075 acc: 6.25 targeted_attack_success: 0.0 ----- OH: 2.57 PPOH: 1.48\n",
            "[48] loss: 12.29064 acc: 3.125 targeted_attack_success: 1.5625 ----- OH: 2.77 PPOH: 1.54\n",
            "[49] loss: 8.054594 acc: 3.125 targeted_attack_success: 10.9375 ----- OH: 2.25 PPOH: 1.21\n",
            "Training class  4\n",
            "[0] loss: 21.48951 acc: 95.3125 targeted_attack_success: 0.0 ----- OH: 0.0 PPOH: 0.0\n",
            "[1] loss: 40.932842 acc: 1.5625 targeted_attack_success: 0.0 ----- OH: 1.87 PPOH: 0.87\n",
            "[2] loss: 23.876007 acc: 6.25 targeted_attack_success: 0.0 ----- OH: 1.03 PPOH: 0.42\n",
            "[3] loss: 15.225684 acc: 10.9375 targeted_attack_success: 0.0 ----- OH: 0.96 PPOH: 0.46\n",
            "[4] loss: 29.135885 acc: 0.0 targeted_attack_success: 0.0 ----- OH: 1.76 PPOH: 0.95\n",
            "[5] loss: 18.344267 acc: 9.375 targeted_attack_success: 0.0 ----- OH: 1.18 PPOH: 0.62\n",
            "[6] loss: 17.599224 acc: 12.5 targeted_attack_success: 0.0 ----- OH: 1.25 PPOH: 0.65\n",
            "[7] loss: 17.758198 acc: 9.375 targeted_attack_success: 0.0 ----- OH: 0.89 PPOH: 0.39\n",
            "[8] loss: 12.811001 acc: 14.0625 targeted_attack_success: 0.0 ----- OH: 0.85 PPOH: 0.34\n",
            "[9] loss: 12.894691 acc: 20.3125 targeted_attack_success: 0.0 ----- OH: 0.78 PPOH: 0.28\n",
            "[10] loss: 15.350416 acc: 18.75 targeted_attack_success: 0.0 ----- OH: 0.85 PPOH: 0.37\n",
            "[11] loss: 22.1903 acc: 4.6875 targeted_attack_success: 0.0 ----- OH: 1.19 PPOH: 0.54\n",
            "[12] loss: 13.370058 acc: 20.3125 targeted_attack_success: 0.0 ----- OH: 1.11 PPOH: 0.46\n",
            "[13] loss: 14.001043 acc: 26.5625 targeted_attack_success: 0.0 ----- OH: 0.78 PPOH: 0.33\n",
            "[14] loss: 25.79691 acc: 6.25 targeted_attack_success: 0.0 ----- OH: 1.14 PPOH: 0.49\n",
            "[15] loss: 14.450726 acc: 15.625 targeted_attack_success: 0.0 ----- OH: 1.0 PPOH: 0.51\n",
            "[16] loss: 11.33897 acc: 25.0 targeted_attack_success: 0.0 ----- OH: 1.06 PPOH: 0.51\n",
            "[17] loss: 16.351917 acc: 9.375 targeted_attack_success: 0.0 ----- OH: 1.04 PPOH: 0.51\n",
            "[18] loss: 17.365707 acc: 14.0625 targeted_attack_success: 0.0 ----- OH: 0.86 PPOH: 0.39\n",
            "[19] loss: 16.46556 acc: 6.25 targeted_attack_success: 0.0 ----- OH: 1.13 PPOH: 0.4\n",
            "[20] loss: 13.915411 acc: 7.8125 targeted_attack_success: 0.0 ----- OH: 1.04 PPOH: 0.48\n",
            "[21] loss: 13.230812 acc: 9.375 targeted_attack_success: 0.0 ----- OH: 0.96 PPOH: 0.44\n",
            "[22] loss: 16.193638 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 0.88 PPOH: 0.3\n",
            "[23] loss: 14.702669 acc: 9.375 targeted_attack_success: 0.0 ----- OH: 1.08 PPOH: 0.43\n",
            "[24] loss: 15.572347 acc: 28.125 targeted_attack_success: 0.0 ----- OH: 0.92 PPOH: 0.33\n",
            "[25] loss: 20.05587 acc: 4.6875 targeted_attack_success: 0.0 ----- OH: 1.12 PPOH: 0.37\n",
            "[26] loss: 14.219393 acc: 9.375 targeted_attack_success: 0.0 ----- OH: 1.1 PPOH: 0.44\n",
            "[27] loss: 13.482195 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 1.23 PPOH: 0.54\n",
            "[28] loss: 13.921415 acc: 20.3125 targeted_attack_success: 0.0 ----- OH: 1.01 PPOH: 0.45\n",
            "[29] loss: 14.022383 acc: 18.75 targeted_attack_success: 0.0 ----- OH: 1.0 PPOH: 0.33\n",
            "[30] loss: 15.401717 acc: 9.375 targeted_attack_success: 0.0 ----- OH: 1.09 PPOH: 0.46\n",
            "[31] loss: 14.247513 acc: 15.625 targeted_attack_success: 0.0 ----- OH: 1.36 PPOH: 0.54\n",
            "[32] loss: 15.526381 acc: 18.75 targeted_attack_success: 0.0 ----- OH: 1.27 PPOH: 0.58\n",
            "[33] loss: 15.476787 acc: 6.25 targeted_attack_success: 0.0 ----- OH: 1.53 PPOH: 0.73\n",
            "[34] loss: 14.159517 acc: 9.375 targeted_attack_success: 0.0 ----- OH: 1.3 PPOH: 0.49\n",
            "[35] loss: 17.324207 acc: 3.125 targeted_attack_success: 0.0 ----- OH: 1.41 PPOH: 0.55\n",
            "[36] loss: 14.199175 acc: 20.3125 targeted_attack_success: 0.0 ----- OH: 1.22 PPOH: 0.52\n",
            "[37] loss: 12.876791 acc: 12.5 targeted_attack_success: 0.0 ----- OH: 1.13 PPOH: 0.53\n",
            "[38] loss: 13.197576 acc: 17.1875 targeted_attack_success: 0.0 ----- OH: 1.19 PPOH: 0.59\n",
            "[39] loss: 13.083647 acc: 14.0625 targeted_attack_success: 0.0 ----- OH: 1.18 PPOH: 0.57\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}